{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import praw - reddit python wrapper\n",
    "import praw\n",
    "#import pushshift API to get comments\n",
    "from pmaw import PushshiftAPI\n",
    "\n",
    "\n",
    "#import envorinment variables\n",
    "import os\n",
    "#the following were set using the following guide - https://github.com/reddit-archive/reddit/wiki/OAuth2\n",
    "r_client_id = os.environ['reddit_client_id']\n",
    "r_secret_key = os.environ['reddit_secret_key']\n",
    "r_username = os.environ['reddit_username']\n",
    "r_password = os.environ['reddit_password']\n",
    "r_app_id = 'Sub_specific_corpus'\n",
    "app_version = 'v0.1'\n",
    "python_version = !python -V\n",
    "r_user_agent = '{}:{}:{} (by u/{})'.format(python_version, r_app_id, app_version, r_username)\n",
    "import logging #not implemented - https://praw.readthedocs.io/en/stable/getting_started/logging.html\n",
    "import datetime as dt\n",
    "import mysql\n",
    "import mysql.connector\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase number of displayed columns to max\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL database creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_SQL():\n",
    "    return mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='20RUNstackHost',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(db_name):\n",
    "    return mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        passwd='20RUNstackHost',\n",
    "        database=db_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_db_exists(cursor, db_name):\n",
    "    cursor.execute(\"SHOW DATABASES LIKE '{}'\".format(db_name))\n",
    "    return bool(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_table_exists(cursor, table_name):\n",
    "    cursor.execute(\"SHOW TABLES LIKE '{}'\".format(table_name))\n",
    "    return bool(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_db(cursor, db_name):\n",
    "    cursor.execute(\"CREATE DATABASE {}\".format(db_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comments_table(cursor):\n",
    "    cursor.execute(\"CREATE TABLE comments (author VARCHAR(40), author_fullname VARCHAR(255),body TEXT, created_utc VARCHAR(255), id VARCHAR(20) PRIMARY KEY, is_submitter VARCHAR(255), link_id VARCHAR(255), parent_id VARCHAR(255), permalink VARCHAR(255), retrieved_on VARCHAR(30), score INT, subreddit VARCHAR(255), subreddit_id VARCHAR(255))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_table_to_db(db_name, table):\n",
    "    cnx_SQL = connect_to_SQL()\n",
    "    cursor_SQL = cnx_SQL.cursor()\n",
    "    if not check_if_db_exists(cursor_SQL, db_name):\n",
    "        add_db(cursor_SQL, db_name)\n",
    "        print('Database {} created'.format(db_name))\n",
    "    cnx_SQL.commit()\n",
    "    cursor_SQL.close()\n",
    "    cnx_SQL.close()\n",
    "    cnx = connect_to_db(db_name)\n",
    "    cursor = cnx.cursor()\n",
    "    if not check_if_table_exists(cursor, table):\n",
    "        if table == 'comments':\n",
    "            add_comments_table(cursor)\n",
    "            print('Table {} created'.format(table))\n",
    "    cnx.commit()\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    print('Table {} added to database {}'.format(table, db_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit API (PRAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if we can use the reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=r_client_id,\n",
    "    client_secret=r_secret_key,\n",
    "    user_agent=r_user_agent,\n",
    "    username=r_username,\n",
    "    password=r_password    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praw.models.listing.generator.ListingGenerator at 0x1e17cd9bd90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('askreddit')\n",
    "subreddit.comments(limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's my go-to right there\n",
      "Everything will be ok, you can still live with one kidney\n",
      "<whispers from shadows> Shhh… It’s OK, it’s part of Prime now.\n",
      "Damn Jackie there you go again being all dramatic!\n",
      "That soundsbinteresting, man. Please don't try to eat the wooddust, haha\n",
      "OB/GYN’s\n",
      "i'd fall onto my backyard because my floor is 10 feet above the ground.\n",
      "Probably the time when the squirrel problem in our yard got so bad (people kept feeding them) that the raccoons started eating the baby squirrels you could hear the screams from our apartment. I've lived in an apartment since I was 11 though so I probably have more lol\n",
      "Ahhhhh.\n",
      "\n",
      "My bad.\n",
      "\n",
      "I apologize.\n",
      "\n",
      "I am unaware of firearm ownership in other countries.\n",
      "\n",
      "I concern myself with the US because so much of what goes on here flies in the face of common sense.\n",
      "You better start smell testing everything before you eat it next time you’re over there\n"
     ]
    }
   ],
   "source": [
    "for i in subreddit.comments(limit=10):\n",
    "    print(i.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsno17q\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for comment in subreddit.comments(limit=1):\n",
    "    print(comment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PushShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the pushshift pmaw API\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments_df(df):\n",
    "    '''\n",
    "    Cleans the comments dataframe by removing columns that are not needed\n",
    "    '''\n",
    "    return df.drop(columns=['all_awardings', 'associated_award', 'author_flair_background_color', 'author_flair_css_class','author_flair_richtext', 'author_flair_template_id', 'author_flair_text',\\\n",
    "        'author_flair_text_color','author_flair_type', 'author_patreon_flair', 'author_premium', 'awarders', 'collapsed_because_crowd_control', 'comment_type', 'gildings','locked','no_follow',\\\n",
    "        'send_replies','stickied','top_awarded_type', 'total_awards_received', 'treatment_tags', 'archived', 'body_sha1', 'can_gild',  'collapsed', 'collapsed_reason', 'controversiality',\\\n",
    "        'distinguished','gilded','score_hidden','subreddit_name_prefixed','subreddit_type','author_cakeday','unrepliable_reason', 'collapsed_reason_code', 'retrieved_utc'], axis=1, errors='ignore')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pushshift_comments(subreddit, before, after, limit):\n",
    "    '''\n",
    "    Gets comments from the pushshift API\n",
    "    '''\n",
    "    return api.search_comments(subreddit=subreddit, metadata=True, before=before, after=after, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pushshift_to_df(comments):\n",
    "    '''\n",
    "    Converts the comments from the pushshift API to a dataframe\n",
    "    '''\n",
    "    comment_list = [c for c in comments]\n",
    "    comments_df = pd.DataFrame(comment_list)\n",
    "    return comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_df_to_db(df, db_name, table):\n",
    "    '''\n",
    "    Sends the dataframe to the database\n",
    "    '''\n",
    "    add_table_to_db(db_name, table)\n",
    "    engine = create_engine('mysql+pymysql://root:20RUNstackHost@localhost/{}'.format(db_name))\n",
    "    df.to_sql(table, con = engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(subreddit, before, after, limit=None):\n",
    "    '''\n",
    "    Gets comments from the pushshift API and sends them to the database\n",
    "    '''\n",
    "    comments = get_pushshift_comments(subreddit, before, after, limit)\n",
    "    comments_df = from_pushshift_to_df(comments)\n",
    "    comments_df = clean_comments_df(comments_df)\n",
    "    send_df_to_db(comments_df, subreddit, 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting start and end date for the data\n",
    "start_date = int(dt.datetime(2021, 1, 1, 0, 0).timestamp())\n",
    "end_date = int(dt.datetime(2022, 1, 1, 0, 0).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:pmaw.PushshiftAPIBase:14413 result(s) available in Pushshift\n",
      "INFO:pmaw.PushshiftAPIBase:Checkpoint:: Success Rate: 100.00% - Requests: 100 - Batches: 10 - Items Remaining: 4432\n",
      "INFO:pmaw.PushshiftAPIBase:Total:: Success Rate: 98.80% - Requests: 167 - Batches: 17 - Items Remaining: 340\n",
      "INFO:pmaw.PushshiftAPIBase:340 result(s) not found in Pushshift\n",
      "Database askreddit created\n",
      "Table comments created\n",
      "Table comments added to database askreddit\n",
      "INFO:pmaw.PushshiftAPIBase:14057 result(s) available in Pushshift\n",
      "INFO:pmaw.PushshiftAPIBase:Checkpoint:: Success Rate: 94.00% - Requests: 100 - Batches: 10 - Items Remaining: 4657\n",
      "INFO:pmaw.PushshiftAPIBase:Total:: Success Rate: 95.27% - Requests: 169 - Batches: 17 - Items Remaining: 301\n",
      "INFO:pmaw.PushshiftAPIBase:301 result(s) not found in Pushshift\n",
      "Table comments added to database askreddit\n",
      "INFO:pmaw.PushshiftAPIBase:11367 result(s) available in Pushshift\n",
      "INFO:pmaw.PushshiftAPIBase:Checkpoint:: Success Rate: 91.00% - Requests: 100 - Batches: 10 - Items Remaining: 2347\n",
      "INFO:pmaw.PushshiftAPIBase:Total:: Success Rate: 89.47% - Requests: 152 - Batches: 16 - Items Remaining: 194\n",
      "INFO:pmaw.PushshiftAPIBase:194 result(s) not found in Pushshift\n",
      "Table comments added to database askreddit\n",
      "INFO:pmaw.PushshiftAPIBase:11583 result(s) available in Pushshift\n"
     ]
    }
   ],
   "source": [
    "#getting all the data at once is a bad idea lets build a loop that does it 5000 dt units at a time\n",
    "while start_date<end_date:\n",
    "    get_comments('askreddit', end_date, end_date-5000)\n",
    "    end_date-=5000"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415b51a014e6e0beb5722367d9da13b1dc115eed8d1c27ed06a75270ca49036a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
